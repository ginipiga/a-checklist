"""
LLMì„ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ë¶„ì„ ë° í”„ë¡œì íŠ¸ êµ¬ì¡°í™”
ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì ì ˆí•œ í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
import json
import os
from typing import Dict, Any, Optional, List

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
DOCUMENT_ANALYSIS_PROMPT = """ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ê³„ì¸µì  ì²´í¬ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ë¬¸ì„œ êµ¬ì¡° íŒŒì‹± ê·œì¹™

ë¬¸ì„œì˜ ê°œìš” ìˆ˜ì¤€(outline level)ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë³€í™˜í•˜ì„¸ìš”:

**ë ˆë²¨ 1 (ë¬¸ì„œ ì œëª©)**
- ë¬¸ì„œ ì „ì²´ë¥¼ ëŒ€í‘œí•˜ëŠ” ê°€ì¥ í° ì œëª©
- ë³´í†µ ë§¨ ìœ„ì— ìœ„ì¹˜í•˜ë©° ë³¼ë“œì²´ì´ê±°ë‚˜ í° ê¸€ì”¨
- ì˜ˆ: "í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì íŠ¸ ìœ„í—˜ê´€ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸"
- â†’ ë£¨íŠ¸ì˜ titleë¡œ ì‚¬ìš©

**ë ˆë²¨ 2 (ì£¼ìš” ì„¹ì…˜)**
- "1.", "2.", "3." ê°™ì€ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì œëª©
- ë˜ëŠ” "ê°€.", "ë‚˜.", "ë‹¤." ê°™ì€ í•œê¸€ ìˆœì„œ
- ì˜ˆ: "1. ê¸°ìˆ  ì¸í”„ë¼ ìœ„í—˜", "2. ë³´ì•ˆ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ìœ„í—˜"
- â†’ children ë°°ì—´ì— í•˜ìœ„ í† ê¸€ë¡œ ì¶”ê°€
- âš ï¸ ë²ˆí˜¸ëŠ” ì œê±°í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ìœ ì§€!

**ë ˆë²¨ 3 (ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©)**
- "â€¢", "-", "â—‹", "â–ª" ê°™ì€ ê¸°í˜¸ë¡œ ì‹œì‘
- ë˜ëŠ” "1)", "ê°€)", "(1)" ê°™ì€ ì†Œë²ˆí˜¸
- ì˜ˆ: "â€¢ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ í˜¸í™˜ì„± ê²€ì¦ ì™„ë£Œ"
- â†’ í•´ë‹¹ ì„¹ì…˜ì˜ checklist ë°°ì—´ì— ì¶”ê°€
- âš ï¸ ê¸°í˜¸(â€¢, -)ëŠ” ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©

**ë ˆë²¨ 4+ (ìƒì„¸ ì„¤ëª…)**
- ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì—†ëŠ” ì¼ë°˜ ë¬¸ì¥
- â†’ ë¬´ì‹œí•˜ê±°ë‚˜ í•´ë‹¹ ì„¹ì…˜ì˜ contentì— ê°„ëµíˆ ìš”ì•½

## ì¶œë ¥ JSON êµ¬ì¡° (ì •í™•íˆ ì´ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”!)

{
  "title": "í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì íŠ¸ ìœ„í—˜ê´€ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸",
  "content": "",
  "checklist": [],
  "children": [
    {
      "title": "1. ê¸°ìˆ  ì¸í”„ë¼ ìœ„í—˜",
      "content": "",
      "checklist": [
        {"text": "í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ í˜¸í™˜ì„± ê²€ì¦ ì™„ë£Œ", "is_checked": false, "score": 10},
        {"text": "ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì¶©ë¶„ì„± í™•ì¸", "is_checked": false, "score": 8},
        {"text": "ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ ìˆ˜ë¦½", "is_checked": false, "score": 12},
        {"text": "ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ì—°ë™ í…ŒìŠ¤íŠ¸ ì™„ë£Œ", "is_checked": false, "score": 10},
        {"text": "ì¬í•´ë³µêµ¬(DR) ê³„íš ìˆ˜ë¦½", "is_checked": false, "score": 15}
      ],
      "children": []
    },
    {
      "title": "2. ë³´ì•ˆ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ìœ„í—˜",
      "content": "",
      "checklist": [
        {"text": "ë°ì´í„° ì•”í˜¸í™” ì •ì±… ìˆ˜ë¦½", "is_checked": false, "score": 12},
        {"text": "ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬ ì²´ê³„ êµ¬ì¶•", "is_checked": false, "score": 10},
        {"text": "ê·œì œ ì¤€ìˆ˜ ìš”êµ¬ì‚¬í•­ ê²€í†  (GDPR, ê°œì¸ì •ë³´ë³´í˜¸ë²• ë“±)", "is_checked": false, "score": 15},
        {"text": "ë³´ì•ˆ ê°ì‚¬ ë° ì·¨ì•½ì  ìŠ¤ìº” ì‹¤ì‹œ", "is_checked": false, "score": 12},
        {"text": "ë°±ì—… ë° ë³µêµ¬ ì ˆì°¨ í…ŒìŠ¤íŠ¸", "is_checked": false, "score": 10}
      ],
      "children": []
    }
  ]
}

## í•„ë“œë³„ ìƒì„¸ ê·œì¹™

**title (ì œëª©)**
- ë ˆë²¨ 1: ë¬¸ì„œ ì œëª© ê·¸ëŒ€ë¡œ
- ë ˆë²¨ 2: ì„¹ì…˜ ì œëª©, ë²ˆí˜¸ í¬í•¨ ("1. ê¸°ìˆ  ì¸í”„ë¼ ìœ„í—˜" â† "1." ìœ ì§€!)
- ìµœëŒ€ 100ì

**content (ë‚´ìš©)**
- ê¸°ë³¸ê°’: ë¹ˆ ë¬¸ìì—´ ""
- ì„¤ëª…ë¬¸ì´ ìˆì„ ë•Œë§Œ 1ì¤„ ìš”ì•½ (ì„ íƒ)
- ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ""ë¡œ ë¹„ì›Œë‘ì„¸ìš”

**checklist (ì²´í¬ë¦¬ìŠ¤íŠ¸ ë°°ì—´)**
- text: í•­ëª© í…ìŠ¤íŠ¸ (â€¢, - ì œê±°)
- is_checked: í•­ìƒ false
- score: 5~20 ì‚¬ì´ì˜ ì •ìˆ˜ (í•­ëª© ì¤‘ìš”ë„/ë‚œì´ë„)

**children (í•˜ìœ„ í† ê¸€ ë°°ì—´)**
- ë ˆë²¨ 1: childrenì— ë ˆë²¨ 2 ì„¹ì…˜ë“¤ í¬í•¨
- ë ˆë²¨ 2: childrenì€ ë¹ˆ ë°°ì—´ []

**score í• ë‹¹ ê¸°ì¤€**
- 5-8: ê°„ë‹¨í•œ í™•ì¸, ë¬¸ì„œ ì½ê¸°
- 9-12: ì¼ë°˜ ì‘ì—…, ê²€í† 
- 13-17: ì¤‘ìš” ì‘ì—…, ìŠ¹ì¸ í•„ìš”
- 18-20: í•µì‹¬ ì‘ì—…, í”„ë¡œì íŠ¸ ì„±íŒ¨ ê²°ì •

## ê¸ˆì§€ì‚¬í•­
- âŒ ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš© ì¶”ê°€ ê¸ˆì§€
- âŒ í•­ëª© ì„ì˜ë¡œ í•©ì¹˜ê±°ë‚˜ ë¶„ë¦¬ ê¸ˆì§€
- âŒ contentì— ê¸´ ì›ë¬¸ ë³µì‚¬ ê¸ˆì§€
- âŒ ì„¹ì…˜ ë²ˆí˜¸ ì œê±° ê¸ˆì§€ (1., 2. ìœ ì§€)
- âŒ ì´ìƒí•œ ë¬¸ì/ë°˜ë³µ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€

## ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ë ˆë²¨ 1 ì œëª©ì„ ë£¨íŠ¸ titleë¡œ ì„¤ì •
- [ ] ë ˆë²¨ 2 ì„¹ì…˜ì„ childrenì— í† ê¸€ë¡œ ì¶”ê°€
- [ ] ë ˆë²¨ 3 í•­ëª©ì„ checklistì— ì¶”ê°€
- [ ] ëª¨ë“  contentëŠ” ""
- [ ] scoreëŠ” 5~20
- [ ] JSONë§Œ ì¶œë ¥, ì„¤ëª… ì—†ìŒ

ìœ„ ê·œì¹™ì„ ì •í™•íˆ ë”°ë¼ ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ JSONìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”."""


class SmartTemplateProcessor:
    """LLMì„ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ë¶„ì„ ë° í…œí”Œë¦¿ ì ìš©"""

    def __init__(self, llm_mode: str = "none"):
        """
        Args:
            llm_mode: LLM ì‚¬ìš© ëª¨ë“œ
                     "none" - LLM ì‚¬ìš© ì•ˆ í•¨ (ê¸°ë³¸ í…œí”Œë¦¿)
                     "ollama" - ë¡œì»¬ Ollama ì‚¬ìš© (ì•ˆì „, ë¬´ë£Œ)
                     "openai" - OpenAI API ì‚¬ìš© (ì •í™•í•˜ì§€ë§Œ ë¹„ìš© ë°œìƒ)
        """
        self.llm_mode = llm_mode.lower()
        self.llm_client = None

        if self.llm_mode == "ollama":
            self._init_ollama()
        elif self.llm_mode == "openai":
            self._init_openai()

    def _init_ollama(self):
        """Ollama ì´ˆê¸°í™”"""
        try:
            import requests
            # Ollama ì„œë²„ í™•ì¸
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                self.llm_client = "ollama"
                print("âœ… ë¡œì»¬ LLM(Ollama) ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ëª¨ë“œ í™œì„±í™”")
                print("   ë°ì´í„°ê°€ ì™¸ë¶€ë¡œ ì „ì†¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            else:
                print("âš ï¸ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.llm_mode = "none"
        except Exception as e:
            print(f"âš ï¸ Ollama ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("   ê¸°ë³¸ í…œí”Œë¦¿ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            self.llm_mode = "none"

    def _init_openai(self):
        """OpenAI ì´ˆê¸°í™”"""
        try:
            import openai
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self.llm_client = openai.OpenAI(api_key=api_key)
                print("âœ… OpenAI ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ëª¨ë“œ í™œì„±í™”")
                print("âš ï¸ ì£¼ì˜: ë¬¸ì„œ ë‚´ìš©ì´ OpenAI ì„œë²„ë¡œ ì „ì†¡ë©ë‹ˆë‹¤.")
            else:
                print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                self.llm_mode = "none"
        except ImportError:
            print("âš ï¸ openai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install openai")
            self.llm_mode = "none"

    def analyze_document(self, filename: str, content: str) -> Optional[Dict[str, Any]]:
        """
        ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

        Args:
            filename: íŒŒì¼ëª…
            content: ë¬¸ì„œ ë‚´ìš©

        Returns:
            Dict: í† ê¸€ êµ¬ì¡° ë°ì´í„°
        """
        if self.llm_mode == "none" or not self.llm_client:
            return None

        try:
            # ë¬¸ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
            max_length = 600  # 600ìë¡œ ëŒ€í­ ì¶•ì†Œ
            if len(content) > max_length:
                content = content[:max_length] + "\n... (ìƒëµ)"

            user_prompt = f"""íŒŒì¼: {filename}

ë‚´ìš©:
{content}"""

            if self.llm_mode == "ollama":
                return self._analyze_with_ollama(user_prompt)
            elif self.llm_mode == "openai":
                return self._analyze_with_openai(user_prompt)

        except Exception as e:
            print(f"âŒ LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def _analyze_with_ollama(self, user_prompt: str) -> Optional[Dict[str, Any]]:
        """Ollamaë¡œ ë¬¸ì„œ ë¶„ì„"""
        try:
            import requests

            print("ğŸ“„ OLLAMA LLMìœ¼ë¡œ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì¤‘...")

            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "qwen2.5:7b",
                    "prompt": f"{DOCUMENT_ANALYSIS_PROMPT}\n\n{user_prompt}",
                    "stream": False,
                    "format": "json",
                    "options": {
                        "temperature": 0.1,
                        "num_predict": 512,  # 512ë¡œ ì¶•ì†Œ
                        "num_ctx": 1024  # ì»¨í…ìŠ¤íŠ¸ë„ ì¶•ì†Œ
                    }
                },
                timeout=90  # 90ì´ˆë¡œ ì¶•ì†Œ
            )

            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "")

                # JSON íŒŒì‹±
                try:
                    data = json.loads(response_text)
                    print("âœ… LLM ë¶„ì„ ì™„ë£Œ")
                    return data
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"   ì‘ë‹µ ë‚´ìš©: {response_text[:200]}...")
                    return None
            else:
                print(f"âš ï¸ Ollama ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return None

        except Exception as e:
            print(f"âš ï¸ Ollama ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def _analyze_with_openai(self, user_prompt: str) -> Optional[Dict[str, Any]]:
        """OpenAIë¡œ ë¬¸ì„œ ë¶„ì„"""
        try:
            response = self.llm_client.chat.completions.create(
                model="gpt-4o-mini",  # ë˜ëŠ” gpt-4
                messages=[
                    {"role": "system", "content": DOCUMENT_ANALYSIS_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7,
                max_tokens=2000
            )

            response_text = response.choices[0].message.content

            # JSON íŒŒì‹±
            try:
                data = json.loads(response_text)
                return data
            except json.JSONDecodeError:
                print("âš ï¸ OpenAI ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

        except Exception as e:
            print(f"âš ï¸ OpenAI ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None


def is_smart_analysis_available(llm_mode: str = "none") -> bool:
    """ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ê¸°ëŠ¥ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸"""
    if llm_mode == "none":
        return False
    elif llm_mode == "ollama":
        try:
            import requests
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
    elif llm_mode == "openai":
        return bool(os.getenv("OPENAI_API_KEY"))
    return False
